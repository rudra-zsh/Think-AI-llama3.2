# Think-AI-llama3.2
Local AI using llama3.2 that stores past conversation on a json file. When launched again, It loads the previous conversation to start from where it left of.
Any model can be used, just change the Model name in Python file. And Change of models can also be done while keeping the memory.


I used ChatGPT extensively.

Requirements :
1. Ollama needs to be installed on the system
2. python3
3. the LLM model should be pulled
